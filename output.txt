
===== File: test/java/com/cap/dis/DisApplicationTests.java =====

package com.cap.dis;

import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;

@SpringBootTest
class DisApplicationTests {

	@Test
	void contextLoads() {
	}

}

========================



===== File: main/java/com/cap/dis/DisDataIngestionApplication.java =====

package com.cap.dis;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.scheduling.annotation.EnableAsync;

@SpringBootApplication
@EnableAsync
public class DisDataIngestionApplication {
    public static void main(String[] args) {
        SpringApplication.run(DisDataIngestionApplication.class, args);
    }
}
========================



===== File: main/java/com/cap/dis/config/KafkaProducerConfig.java =====

package com.cap.dis.config;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
========================



===== File: main/java/com/cap/dis/service/KafkaProducerService.java =====

package com.cap.dis.service;

import lombok.RequiredArgsConstructor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Service;

import java.util.concurrent.CompletableFuture;

@Service
@RequiredArgsConstructor
public class KafkaProducerService {

    private static final Logger log = LoggerFactory.getLogger(KafkaProducerService.class);

    private final KafkaTemplate<String, String> kafkaTemplate;

    @Value("${kafka.topic}")
    private String topic;

    public void sendMessage(String message) {
        CompletableFuture<SendResult<String, String>> future = kafkaTemplate.send(topic, message);
        future.whenComplete((result, ex) -> {
            if (ex == null) {
                log.info("Sent message to Kafka topic {}: {}", topic, message);
            } else {
                log.error("Failed to send message to Kafka topic {}: {}", topic, ex.getMessage());
            }
        });
    }
}
========================



===== File: main/java/com/cap/dis/service/UdpListenerService.java =====

package com.cap.dis.service;

import edu.nps.moves.dis.EntityStatePdu;
import edu.nps.moves.dis.FirePdu;
import edu.nps.moves.dis.Pdu;
import edu.nps.moves.disutil.PduFactory;
import lombok.RequiredArgsConstructor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

import javax.annotation.PostConstruct;
import java.net.DatagramPacket;
import java.net.DatagramSocket;
import java.util.Arrays;

@Service
@RequiredArgsConstructor
public class UdpListenerService {

    private static final Logger log = LoggerFactory.getLogger(UdpListenerService.class);

    @Value("${udp.port}")
    private int port;

    @Value("${udp.buffer-size}")
    private int bufferSize;

    private final KafkaProducerService kafkaProducerService;

    private final PduFactory pduFactory = new PduFactory();

    @PostConstruct
    public void init() {
        startListening();
    }

    @Async
    public void startListening() {
        try (DatagramSocket socket = new DatagramSocket(port)) {
            byte[] buffer = new byte[bufferSize];
            log.info("UDP Listener started on port {}", port);
            while (true) {
                DatagramPacket packet = new DatagramPacket(buffer, buffer.length);
                socket.receive(packet);
                byte[] rawData = Arrays.copyOfRange(packet.getData(), 0, packet.getLength());
                String decodedData = decodeDisPdu(rawData);
                kafkaProducerService.sendMessage(decodedData);
            }
        } catch (Exception e) {
            log.error("Error in UDP listener", e);
            System.exit(1);
        }
    }

    private String decodeDisPdu(byte[] rawData) {
        try {
            Pdu pdu = pduFactory.createPdu(rawData);
            if (pdu != null) {
                return pduToJson(pdu);
            } else {
                log.warn("Received unknown PDU type");
                return "{\"error\":\"Unknown PDU type\"}";
            }
        } catch (Exception e) {
            log.error("Failed to decode PDU", e);
            return "{\"error\":\"Error decoding PDU\"}";
        }
    }

    private String pduToJson(Pdu pdu) {
        StringBuilder json = new StringBuilder("{");
        json.append("\"type\":\"").append(pdu.getClass().getSimpleName()).append("\",");
        json.append("\"protocolVersion\":").append(pdu.getProtocolVersion()).append(",");
        json.append("\"exerciseID\":").append(pdu.getExerciseID()).append(",");
        json.append("\"pduType\":").append(pdu.getPduType()).append(",");
        json.append("\"timestamp\":").append(pdu.getTimestamp()).append(",");

        if (pdu instanceof EntityStatePdu esp) {
            json.append("\"entityId\":{");
            json.append("\"site\":").append(esp.getEntityID().getSite()).append(",");
            json.append("\"application\":").append(esp.getEntityID().getApplication()).append(",");
            json.append("\"entity\":").append(esp.getEntityID().getEntity());
            json.append("},");
            json.append("\"location\":{");
            json.append("\"x\":").append(esp.getEntityLocation().getX()).append(",");
            json.append("\"y\":").append(esp.getEntityLocation().getY()).append(",");
            json.append("\"z\":").append(esp.getEntityLocation().getZ());
            json.append("}");
        } else if (pdu instanceof FirePdu fp) {
            json.append("\"firingEntityId\":{");
            json.append("\"site\":").append(fp.getFiringEntityID().getSite()).append(",");
            json.append("\"application\":").append(fp.getFiringEntityID().getApplication()).append(",");
            json.append("\"entity\":").append(fp.getFiringEntityID().getEntity());
            json.append("},");
            json.append("\"targetEntityId\":{");
            json.append("\"site\":").append(fp.getTargetEntityID().getSite()).append(",");
            json.append("\"application\":").append(fp.getTargetEntityID().getApplication()).append(",");
            json.append("\"entity\":").append(fp.getTargetEntityID().getEntity());
            json.append("},");
            json.append("\"munitionId\":{");
            json.append("\"site\":").append(fp.getMunitionID().getSite()).append(",");
            json.append("\"application\":").append(fp.getMunitionID().getApplication()).append(",");
            json.append("\"entity\":").append(fp.getMunitionID().getEntity());
            json.append("}");
        } else {
            json.append("\"details\":\"Unhandled PDU type, basic metadata only\"");
        }

        json.append(",\"processedAt\":").append(System.currentTimeMillis()).append("}");
        return json.toString();
    }
}
========================



===== File: main/resources/application.properties =====

spring.application.name=dis

# The port on which the Spring Boot app runs
server.port=8080

# UDP Listener Configuration
udp.port=3000
udp.buffer-size=2048

# Kafka Configuration
spring.kafka.bootstrap-servers=localhost:9092
kafka.topic=dis-pdus
========================


